{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-20T13:05:18.540338Z",
     "start_time": "2024-07-20T13:05:15.094988Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importations nécessaires\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a61abede978f71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "base_logdir = \"./logs\"\n",
    "seed = 42\n",
    "batch_size = 1\n",
    "epochs = 100\n",
    "lr = 0.001\n",
    "img_height, img_width = 32, 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "004fda7a-12b5-4d72-b1e1-5ef5b9acf58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixer les graines aléatoires pour la reproductibilité\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c583c04-8a21-4a6c-be03-bd3f6ba3ba82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définir le nom de l'expérience\n",
    "experiment_name = f\"mlp_dataset_seed_{seed}_bs_{batch_size}_lr_{lr}\"\n",
    "final_log_dir = os.path.join(base_logdir, experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bfd648ce-3fec-4b34-8dff-01852b388ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de normalisation Z-score\n",
    "def z_score_normalize(data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    return (data - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "228dbb17-1321-43b3-9a18-b94976f9bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d'encodage des étiquettes\n",
    "def encode_labels(labels):\n",
    "    encoded = []\n",
    "    for label in labels:\n",
    "        if label == 0:  # metal\n",
    "            encoded.append([1, -1, -1])\n",
    "        elif label == 1:  # paper\n",
    "            encoded.append([-1, 1, -1])\n",
    "        else:  # plastic\n",
    "            encoded.append([-1, -1, 1])\n",
    "    return np.array(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a997a07-beb1-48a8-8386-c71865297e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de chargement et prétraitement des images\n",
    "def load_and_preprocess_image(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=1)\n",
    "    img = tf.image.resize(img, [img_height, img_width])\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    img = z_score_normalize(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b66518ef-cf3f-4b4d-9f08-1d3f0361107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30154 images belonging to 3 classes.\n",
      "Found 3208 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Générateurs de données\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=z_score_normalize)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=z_score_normalize)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    '../../dataset/train',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    '../../dataset/test',\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='grayscale'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7cbfe276-ba8f-419b-8aff-259c35b80a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder les étiquettes\n",
    "train_generator.classes = encode_labels(train_generator.classes)\n",
    "test_generator.classes = encode_labels(test_generator.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf24555e-f283-4687-9d08-0a9388750c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition du modèle\n",
    "model = Sequential([\n",
    "    Input(shape=(img_height, img_width, 1)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='tanh'),\n",
    "    Dense(128, activation='tanh'),\n",
    "    Dense(64, activation='tanh'),\n",
    "    Dense(3, activation='tanh')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b8aef0b-3fa4-47ae-aaf4-db0a2d5b895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilation du modèle\n",
    "optimizer = SGD(learning_rate=lr, momentum=0.0)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97982931-d2b3-4f4a-bd72-3e6f9bd9f9fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m   30/30154\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:05\u001b[0m 4ms/step - accuracy: 0.3433 - loss: 0.7691       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/esgi/3BigData/.venv/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  106/30154\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:03\u001b[0m 4ms/step - accuracy: 0.4117 - loss: 0.7284"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/esgi/3BigData/.venv/lib/python3.12/site-packages/PIL/Image.py:1056: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20288/30154\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m51s\u001b[0m 5ms/step - accuracy: 0.4795 - loss: nan "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46036/1367856415.py:5: RuntimeWarning: invalid value encountered in divide\n",
      "  return (data - mean) / std\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30154/30154\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 6ms/step - accuracy: 0.4496 - loss: nan - val_accuracy: 0.0000e+00 - val_loss: nan\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 16:05:15.743226: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/usr/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n",
      "2024-07-20 16:05:15.765975: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Entraînement du modèle\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Entraînement du modèle\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mTensorBoard\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlog_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfinal_log_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/esgi/3BigData/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/esgi/3BigData/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:354\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_epoch_iterator \u001b[38;5;241m=\u001b[39m TFEpochIterator(\n\u001b[1;32m    334\u001b[0m             x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    335\u001b[0m             y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    341\u001b[0m             shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    342\u001b[0m         )\n\u001b[1;32m    343\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[1;32m    344\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m    345\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    351\u001b[0m         _use_cached_eval_dataset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    352\u001b[0m     )\n\u001b[1;32m    353\u001b[0m     val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m--> 354\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m \u001b[43mval_logs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m()\n\u001b[1;32m    355\u001b[0m     }\n\u001b[1;32m    356\u001b[0m     epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n\u001b[1;32m    358\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_end(epoch, epoch_logs)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entraînement du modèle\n",
    "# Entraînement du modèle\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=[TensorBoard(log_dir=final_log_dir)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa77b394-292a-4631-ab86-570b883261a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation des résultats\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb168e-7231-44d9-a955-84bbfe88b921",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sauvegarde du modèle\n",
    "model.save('mlp_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
